{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models, utils, parsing\n",
    "from collections import defaultdict, Counter\n",
    "from pprint import pprint\n",
    "import os\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_dir = \"accessible-test/\" \n",
    "metadata_file = \"aaccp-docMetadata.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates metadata and minimally cleans each article file; then tokenizes\n",
    "def process_docs(base_dir):\n",
    "\n",
    "    articleCount = 0\n",
    "    papers = os.listdir(base_dir)\n",
    "\n",
    "    for paper in papers:\n",
    "        if not paper.startswith('.'):\n",
    "            print(\"Opening: \", paper)\n",
    "        \n",
    "            issues = os.listdir(base_dir + \"/\" + paper)\n",
    "        \n",
    "            for issue in issues:\n",
    "                if not issue.startswith('.'):\n",
    "                    # print(\"Opening issue: \", issue)\n",
    "\n",
    "                    # get some metadata\n",
    "                    issueYear = issue[0:4]\n",
    "                    issueMonth = issue[4:6]\n",
    "                    if len(issue) < 8:\n",
    "                        issueDay = \"01\"\n",
    "                    else:\n",
    "                        issueDay = issue[6:8]\n",
    "\n",
    "                    articles = os.listdir(base_dir + \"/\" + paper + \"/\" + issue)\n",
    "\n",
    "                    for article in articles:\n",
    "                        if not article.startswith('.'):\n",
    "                            # print(\"Reading article: \", article)\n",
    "                            articleFile = open(base_dir + \"/\" + paper + \"/\" + issue + \"/\" + article, \"r\")\n",
    "                            articleText = articleFile.read()\n",
    "                            articleFile.close()\n",
    "                        \n",
    "                            # first write the metadata line\n",
    "                            # in format: doc #, path to file, PAPERID, YYYY, MM, DD, TITLE, URL  \n",
    "                            # WILL NEED TO FIGURE OUT PAPERID, TITLE, AND URL LATER; FOR NOW JUST HOLD SPACE\n",
    "                            articleMetadata = str(articleCount) + \",\" + paper + \"/\" + issue + \"/\" + article + \",PAPERID,\" + issueYear + \",\" + issueMonth + \",\" + issueDay + \",HEADLINE,URL\\n\" \n",
    "\n",
    "                            #print(articleMetadata)\n",
    "                            with open(metadata_file, \"a\") as myfile:\n",
    "                                myfile.write(articleMetadata)\n",
    "                        \n",
    "                            # now create the BoW for the article\n",
    "                            articleWords = []\n",
    "               \n",
    "                            # ignore single-char words and words with numbers in them                        \n",
    "                            for word in re.split('\\W+', articleText):\n",
    "                                if len(word) > 1 and not any(char.isdigit() for char in word):\n",
    "                                    articleWords.append(word)\n",
    "                        \n",
    "                            wordString = ' '.join(articleWords)\n",
    "                        \n",
    "                            # increment the article count\n",
    "                            articleCount += 1\n",
    "                            yield utils.tokenize(wordString, lowercase=True)\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCorpus(object):\n",
    "    def __init__(self, base_dir):\n",
    "        self.base_dir = base_dir\n",
    "        self.dictionary = corpora.Dictionary(process_docs(base_dir))\n",
    "        self.dictionary.filter_n_most_frequent(50) # filter 50 most frequent instead of stopwords\n",
    "                                             \n",
    "    def __iter__(self):\n",
    "        for tokens in process_docs(self.base_dir):\n",
    "            yield self.dictionary.doc2bow(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening:  FreedomsJournal\n",
      "Opening:  FrederickDouglassPaper\n",
      "Opening:  NationalAntiSlaveryStandard\n",
      "Opening:  TheColoredAmerican\n",
      "Opening:  TheNorthStar\n",
      "Opening:  TheChristianRecorder\n",
      "Opening:  TheNationalEra\n",
      "Opening:  ProvincialFreeman\n",
      "Opening:  GodeysLadysBook\n",
      "Opening:  TheLiberator\n",
      "Opening:  WeeklyAdvocate\n",
      "Opening:  TheLily\n",
      "Opening:  DouglassMonthly\n",
      "Opening:  ColoredConventions\n",
      "Opening:  FrankLesliesWeekly\n",
      "Created corpus.\n",
      "Dictionary(1171215 unique tokens: ['about', 'administered', 'aforesaid', 'after', 'ager']...)\n",
      "Starting LDA....\n",
      "Opening:  FreedomsJournal\n",
      "Opening:  FrederickDouglassPaper\n",
      "Opening:  NationalAntiSlaveryStandard\n",
      "Opening:  TheColoredAmerican\n",
      "Opening:  TheNorthStar\n",
      "Opening:  TheChristianRecorder\n",
      "Opening:  TheNationalEra\n",
      "Opening:  ProvincialFreeman\n",
      "Opening:  GodeysLadysBook\n",
      "Opening:  TheLiberator\n",
      "Opening:  WeeklyAdvocate\n",
      "Opening:  TheLily\n",
      "Opening:  DouglassMonthly\n",
      "Opening:  ColoredConventions\n",
      "Opening:  FrankLesliesWeekly\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command '/Applications/mallet-2.0.8/bin/mallet train-topics --input /var/folders/mz/491r9g5s2gjfdd83trwyp4y80000gp/T/fa9b8c_corpus.mallet --num-topics 100  --alpha 50 --optimize-interval 0 --num-threads 10 --output-state /var/folders/mz/491r9g5s2gjfdd83trwyp4y80000gp/T/fa9b8c_state.mallet.gz --output-doc-topics /var/folders/mz/491r9g5s2gjfdd83trwyp4y80000gp/T/fa9b8c_doctopics.txt --output-topic-keys /var/folders/mz/491r9g5s2gjfdd83trwyp4y80000gp/T/fa9b8c_topickeys.txt --num-iterations 1000 --inferencer-filename /var/folders/mz/491r9g5s2gjfdd83trwyp4y80000gp/T/fa9b8c_inferencer.mallet --doc-topics-threshold 0.0' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-df87bdaf882f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# this function creates model and saves it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mlda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrappers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLdaMallet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/Applications/mallet-2.0.8/bin/mallet\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid2word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mid2word\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_topics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mlda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'aaccp-ldamodelmallet.lda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/gensim/models/wrappers/ldamallet.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, mallet_path, corpus, num_topics, alpha, id2word, workers, prefix, optimize_interval, iterations, topic_threshold)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miterations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfinferencer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/gensim/models/wrappers/ldamallet.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, corpus)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0;31m# NOTE \"--keep-sequence-bigrams\" / \"--use-ngrams true\" poorer results + runs out of memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"training MALLET LDA with %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m         \u001b[0mcheck_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshell\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_topics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_word_topics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0;31m# NOTE - we are still keeping the wordtopics variable to not break backward compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/gensim/utils.py\u001b[0m in \u001b[0;36mcheck_output\u001b[0;34m(stdout, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m   1804\u001b[0m             \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCalledProcessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1805\u001b[0m             \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1806\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1807\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1808\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command '/Applications/mallet-2.0.8/bin/mallet train-topics --input /var/folders/mz/491r9g5s2gjfdd83trwyp4y80000gp/T/fa9b8c_corpus.mallet --num-topics 100  --alpha 50 --optimize-interval 0 --num-threads 10 --output-state /var/folders/mz/491r9g5s2gjfdd83trwyp4y80000gp/T/fa9b8c_state.mallet.gz --output-doc-topics /var/folders/mz/491r9g5s2gjfdd83trwyp4y80000gp/T/fa9b8c_doctopics.txt --output-topic-keys /var/folders/mz/491r9g5s2gjfdd83trwyp4y80000gp/T/fa9b8c_topickeys.txt --num-iterations 1000 --inferencer-filename /var/folders/mz/491r9g5s2gjfdd83trwyp4y80000gp/T/fa9b8c_inferencer.mallet --doc-topics-threshold 0.0' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "# corpus = MyCorpus('accessible-v4.0-small')\n",
    "corpus = MyCorpus('accessible-ccp')\n",
    "print(\"Created corpus.\")\n",
    "\n",
    "id2word = corpus.dictionary\n",
    "print(id2word)\n",
    "\n",
    "# Starting LDA\n",
    "print(\"Starting LDA....\")\n",
    "\n",
    "# this function creates model and saves it\n",
    "lda = models.wrappers.LdaMallet(\"/Applications/mallet-2.0.8/bin/mallet\", corpus, id2word = id2word, num_topics = 100, workers = 6)\n",
    "\n",
    "lda.save('aaccp-ldamodelmallet.lda')\n",
    "\n",
    "x=lda.load_document_topics()\n",
    "\n",
    "result = lda.show_topics(100, 100, formatted = False)\n",
    "\n",
    "# write topics to file\n",
    "fout = open(\"aaccp-all_newspapers_topics.txt\", \"w\")\n",
    "\n",
    "for each in result:\n",
    "    fout.write(str(each) + \"\\n\")\n",
    "\n",
    "fout.close()\n",
    "    \n",
    "# write doc topics to a file\n",
    "\n",
    "gen = lda.read_doctopics(lda.fdoctopics())\n",
    "\n",
    "fout = open(\"aaccp-all_newspapers_doc_topics.txt\", \"w\")\n",
    "\n",
    "for i in gen:\n",
    "    fout.write(str(i) + \"\\n\")\n",
    "fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now try to pair topics to docs \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
