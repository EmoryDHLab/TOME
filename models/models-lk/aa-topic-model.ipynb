{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models, utils, parsing\n",
    "from collections import defaultdict, Counter\n",
    "from pprint import pprint\n",
    "import os\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_dir = \"accessible-test/\" \n",
    "metadata_file = \"aa-docMetadata.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start the metadatafile\n",
    "\n",
    "metadataFile = open(metadata_file,\"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates metadata and minimally cleans each article file; then tokenizes\n",
    "def process_docs(base_dir):\n",
    "\n",
    "    articleCount = 0\n",
    "    papers = os.listdir(base_dir)\n",
    "\n",
    "    for paper in papers:\n",
    "        if not paper.startswith('.'):\n",
    "            print(\"Opening: \", paper)\n",
    "        \n",
    "            issues = os.listdir(base_dir + \"/\" + paper)\n",
    "        \n",
    "            for issue in issues:\n",
    "                if not issue.startswith('.'):\n",
    "                    # print(\"Opening issue: \", issue)\n",
    "\n",
    "                    # get some metadata\n",
    "                    issueYear = issue[0:4]\n",
    "                    issueMonth = issue[4:6]\n",
    "                    if len(issue) < 8:\n",
    "                        issueDay = \"01\"\n",
    "                    else:\n",
    "                        issueDay = issue[6:8]\n",
    "\n",
    "                    articles = os.listdir(base_dir + \"/\" + paper + \"/\" + issue)\n",
    "\n",
    "                    for article in articles:\n",
    "                        if not article.startswith('.'):\n",
    "                            # print(\"Reading article: \", article)\n",
    "                            articleFile = open(base_dir + \"/\" + paper + \"/\" + issue + \"/\" + article, \"r\")\n",
    "                            articleText = articleFile.read()\n",
    "                            articleFile.close()\n",
    "                        \n",
    "                            # first write the metadata line\n",
    "                            # in format: ##, path to file, PAPERID, YYYY, MM, DD, TITLE, URL  \n",
    "                            # WILL NEED TO FIGURE OUT PAPERID, TITLE, AND URL LATER; FOR NOW JUST HOLD SPACE\n",
    "                            articleMetadata = str(articleCount) + \",\" + paper + \"/\" + issue + \"/\" + article + \",PAPERID,\" + issueYear + \",\" + issueMonth + \",\" + issueDay + \",HEADLINE,URL\" \n",
    "                            print(articleMetadata,file=metadataFile)\n",
    "                        \n",
    "                            # now create the BoW for the article\n",
    "                            articleWords = []\n",
    "               \n",
    "                            # ignore single-char words and words with numbers in them                        \n",
    "                            for word in re.split('\\W+', articleText):\n",
    "                                if len(word) > 1 and not any(char.isdigit() for char in word):\n",
    "                                    articleWords.append(word)\n",
    "                        \n",
    "                            wordString = ' '.join(articleWords)\n",
    "                        \n",
    "                            yield utils.tokenize(wordString, lowercase=True)\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCorpus(object):\n",
    "    def __init__(self, base_dir):\n",
    "        self.base_dir = base_dir\n",
    "        self.dictionary = corpora.Dictionary(process_docs(base_dir))\n",
    "        self.dictionary.filter_n_most_frequent(50) # filter 50 most frequent instead of stopwords\n",
    "                                             \n",
    "    def __iter__(self):\n",
    "        for tokens in process_docs(self.base_dir):\n",
    "            yield self.dictionary.doc2bow(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening:  FreedomsJournal\n",
      "Opening:  FrederickDouglassPaper\n",
      "Opening:  NationalAntiSlaveryStandard\n",
      "Opening:  TheColoredAmerican\n",
      "Opening:  TheNorthStar\n",
      "Opening:  TheChristianRecorder\n",
      "Opening:  TheNationalEra\n",
      "Opening:  ProvincialFreeman\n",
      "Opening:  GodeysLadysBook\n",
      "Opening:  TheLiberator\n",
      "Opening:  WeeklyAdvocate\n",
      "Opening:  TheLily\n",
      "Opening:  DouglassMonthly\n",
      "Opening:  FrankLesliesWeekly\n",
      "Created corpus.\n",
      "Dictionary(1170843 unique tokens: ['about', 'administered', 'aforesaid', 'after', 'ager']...)\n",
      "Starting LDA....\n",
      "Opening:  FreedomsJournal\n",
      "Opening:  FrederickDouglassPaper\n",
      "Opening:  NationalAntiSlaveryStandard\n",
      "Opening:  TheColoredAmerican\n",
      "Opening:  TheNorthStar\n",
      "Opening:  TheChristianRecorder\n",
      "Opening:  TheNationalEra\n",
      "Opening:  ProvincialFreeman\n",
      "Opening:  GodeysLadysBook\n",
      "Opening:  TheLiberator\n",
      "Opening:  WeeklyAdvocate\n",
      "Opening:  TheLily\n",
      "Opening:  DouglassMonthly\n",
      "Opening:  FrankLesliesWeekly\n"
     ]
    }
   ],
   "source": [
    "corpus = MyCorpus('accessible-v4.0-small')\n",
    "print(\"Created corpus.\")\n",
    "\n",
    "id2word = corpus.dictionary\n",
    "print(id2word)\n",
    "\n",
    "# Starting LDA\n",
    "print(\"Starting LDA....\")\n",
    "\n",
    "# this function creates model and saves it\n",
    "lda = models.wrappers.LdaMallet(\"/Applications/mallet-2.0.8/bin/mallet\", corpus, id2word = id2word, num_topics = 100, workers = 2)\n",
    "\n",
    "lda.save('lk-ldamodelmallet-optimized.lda')\n",
    "\n",
    "x=lda.load_document_topics()\n",
    "\n",
    "result = lda.show_topics(100, 100, formatted = False)\n",
    "\n",
    "# write topics to file\n",
    "fout = open(\"lk-all_newspapers_topics.txt\", \"w\")\n",
    "\n",
    "for each in result:\n",
    "    fout.write(str(each) + \"\\n\")\n",
    "\n",
    "fout.close()\n",
    "    \n",
    "# write doc topics to a file\n",
    "\n",
    "gen = lda.read_doctopics(lda.fdoctopics())\n",
    "\n",
    "fout = open(\"lk-all_newspapers_doc_topics.txt\", \"w\")\n",
    "\n",
    "for i in gen:\n",
    "    fout.write(str(i) + \"\\n\")\n",
    "fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting LDA....\n",
      "Opening:  NationalAntiSlaveryStandard\n",
      "Opening issue:  18400618\n",
      "Reading article:  003.txt\n",
      "Reading article:  002.txt\n",
      "Reading article:  001.txt\n",
      "Reading article:  005.txt\n",
      "Reading article:  004.txt\n",
      "Opening issue:  18400611\n",
      "Reading article:  003.txt\n",
      "Reading article:  002.txt\n",
      "Reading article:  001.txt\n",
      "Reading article:  005.txt\n",
      "Reading article:  004.txt\n",
      "Opening issue:  18400625\n",
      "Reading article:  003.txt\n",
      "Reading article:  002.txt\n",
      "Reading article:  001.txt\n",
      "Reading article:  005.txt\n",
      "Reading article:  004.txt\n",
      "Reading article:  006.txt\n",
      "Opening:  DouglassMonthly\n",
      "Opening issue:  185901\n",
      "Reading article:  vim\n",
      "Reading article:  003.txt\n",
      "Reading article:  017.txt\n",
      "Reading article:  016.txt\n",
      "Reading article:  002.txt\n",
      "Reading article:  014.txt\n",
      "Reading article:  000.txt\n",
      "Reading article:  028.txt\n",
      "Reading article:  029.txt\n",
      "Reading article:  001.txt\n",
      "Reading article:  015.txt\n",
      "Reading article:  011.txt\n",
      "Reading article:  005.txt\n",
      "Reading article:  004.txt\n",
      "Reading article:  010.txt\n",
      "Reading article:  006.txt\n",
      "Reading article:  012.txt\n",
      "Reading article:  013.txt\n",
      "Reading article:  007.txt\n",
      "Reading article:  022.txt\n",
      "Reading article:  036.txt\n",
      "Reading article:  037.txt\n",
      "Reading article:  023.txt\n",
      "Reading article:  035.txt\n",
      "Reading article:  021.txt\n",
      "Reading article:  009.txt\n",
      "Reading article:  008.txt\n",
      "Reading article:  020.txt\n",
      "Reading article:  034.txt\n",
      "Reading article:  018.txt\n",
      "Reading article:  030.txt\n",
      "Reading article:  024.txt\n",
      "Reading article:  025.txt\n",
      "Reading article:  031.txt\n",
      "Reading article:  019.txt\n",
      "Reading article:  027.txt\n",
      "Reading article:  033.txt\n",
      "Reading article:  032.txt\n",
      "Reading article:  026.txt\n",
      "Opening issue:  185903\n",
      "Reading article:  060.txt\n",
      "Reading article:  048.txt\n",
      "Reading article:  049.txt\n",
      "Reading article:  059.txt\n",
      "Reading article:  058.txt\n",
      "Reading article:  003.txt\n",
      "Reading article:  017.txt\n",
      "Reading article:  016.txt\n",
      "Reading article:  002.txt\n",
      "Reading article:  014.txt\n",
      "Reading article:  000.txt\n",
      "Reading article:  028.txt\n",
      "Reading article:  029.txt\n",
      "Reading article:  001.txt\n",
      "Reading article:  015.txt\n",
      "Reading article:  039.txt\n",
      "Reading article:  011.txt\n",
      "Reading article:  005.txt\n",
      "Reading article:  004.txt\n",
      "Reading article:  010.txt\n",
      "Reading article:  038.txt\n",
      "Reading article:  006.txt\n",
      "Reading article:  012.txt\n",
      "Reading article:  013.txt\n",
      "Reading article:  007.txt\n",
      "Reading article:  022.txt\n",
      "Reading article:  036.txt\n",
      "Reading article:  037.txt\n",
      "Reading article:  023.txt\n",
      "Reading article:  035.txt\n",
      "Reading article:  021.txt\n",
      "Reading article:  009.txt\n",
      "Reading article:  008.txt\n",
      "Reading article:  020.txt\n",
      "Reading article:  034.txt\n",
      "Reading article:  018.txt\n",
      "Reading article:  030.txt\n",
      "Reading article:  024.txt\n",
      "Reading article:  025.txt\n",
      "Reading article:  031.txt\n",
      "Reading article:  019.txt\n",
      "Reading article:  027.txt\n",
      "Reading article:  033.txt\n",
      "Reading article:  032.txt\n",
      "Reading article:  026.txt\n",
      "Reading article:  041.txt\n",
      "Reading article:  055.txt\n",
      "Reading article:  054.txt\n",
      "Reading article:  040.txt\n",
      "Reading article:  056.txt\n",
      "Reading article:  042.txt\n",
      "Reading article:  043.txt\n",
      "Reading article:  057.txt\n",
      "Reading article:  053.txt\n",
      "Reading article:  047.txt\n",
      "Reading article:  046.txt\n",
      "Reading article:  052.txt\n",
      "Reading article:  044.txt\n",
      "Reading article:  050.txt\n",
      "Reading article:  051.txt\n",
      "Reading article:  045.txt\n",
      "Opening issue:  185902\n",
      "Reading article:  048.txt\n",
      "Reading article:  049.txt\n",
      "Reading article:  003.txt\n",
      "Reading article:  017.txt\n",
      "Reading article:  016.txt\n",
      "Reading article:  002.txt\n",
      "Reading article:  014.txt\n",
      "Reading article:  000.txt\n",
      "Reading article:  028.txt\n",
      "Reading article:  029.txt\n",
      "Reading article:  001.txt\n",
      "Reading article:  015.txt\n",
      "Reading article:  039.txt\n",
      "Reading article:  011.txt\n",
      "Reading article:  005.txt\n",
      "Reading article:  004.txt\n",
      "Reading article:  010.txt\n",
      "Reading article:  038.txt\n",
      "Reading article:  006.txt\n",
      "Reading article:  012.txt\n",
      "Reading article:  013.txt\n",
      "Reading article:  007.txt\n",
      "Reading article:  022.txt\n",
      "Reading article:  036.txt\n",
      "Reading article:  037.txt\n",
      "Reading article:  023.txt\n",
      "Reading article:  035.txt\n",
      "Reading article:  021.txt\n",
      "Reading article:  009.txt\n",
      "Reading article:  008.txt\n",
      "Reading article:  020.txt\n",
      "Reading article:  034.txt\n",
      "Reading article:  018.txt\n",
      "Reading article:  030.txt\n",
      "Reading article:  024.txt\n",
      "Reading article:  025.txt\n",
      "Reading article:  031.txt\n",
      "Reading article:  019.txt\n",
      "Reading article:  027.txt\n",
      "Reading article:  033.txt\n",
      "Reading article:  032.txt\n",
      "Reading article:  026.txt\n",
      "Reading article:  041.txt\n",
      "Reading article:  040.txt\n",
      "Reading article:  042.txt\n",
      "Reading article:  043.txt\n",
      "Reading article:  047.txt\n",
      "Reading article:  046.txt\n",
      "Reading article:  044.txt\n",
      "Reading article:  050.txt\n",
      "Reading article:  045.txt\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
